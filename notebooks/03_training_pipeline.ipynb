{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processed Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from c:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\data\\processed\\preprocessed_full_dataset.csv\n",
      "Loaded dataset with 100000 rows and 32 columns\n",
      "Loading data from c:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\data\\processed\\preprocessed_dataset_first_10k_rows.csv\n",
      "Loaded dataset with 10000 rows and 32 columns\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Add project to path so we can import our modules\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "# Import functionality from our source code\n",
    "import src.data_loading.data_loader as data_loader\n",
    "importlib.reload(data_loader)\n",
    "from src.data_loading.data_loader import load_data, get_numerical_features, get_categorical_features\n",
    "\n",
    "# Loading preprocessed dataset\n",
    "script_dir  = pathlib.Path.cwd()              \n",
    "project_root = script_dir.parent\n",
    "\n",
    "file_path_full_df = project_root / 'data' / 'processed' / 'preprocessed_full_dataset.csv'\n",
    "file_path_first_10k_rows = project_root / 'data' / 'processed' / 'preprocessed_dataset_first_10k_rows.csv'\n",
    "\n",
    "df_full = load_data(str(file_path_full_df))\n",
    "df_first_10k_rows = load_data(str(file_path_first_10k_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose here if to use the df full or 10k rows (faster computations but less reliable results)\n",
    "\n",
    "#df = df_full \n",
    "\n",
    "df = df_first_10k_rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Score Classification Pipeline (End-to-End)\n",
    "\n",
    "This script executes a modular, reproducible, and configurable machine learning pipeline for multi-class credit score classification, using XGBoost and an extended preprocessing + tuning architecture. The pipeline is implemented using a custom CreditScorePipeline class, which encapsulates all steps from data preparation to evaluation.\n",
    "\n",
    "Pipeline Overview and Key Responsibilities\n",
    "\n",
    "The pipeline performs the following key tasks:\n",
    "\n",
    "  - Data Splitting\n",
    "\n",
    "    - Splits the dataset into training, validation, and test sets using stratified sampling to preserve class distributions.\n",
    "\n",
    "    - Ensures independence between hyperparameter tuning (via validation set) and final model evaluation (via test set).\n",
    "\n",
    "  - Preprocessing Setup\n",
    "\n",
    "    - Loads configurations (e.g., encoding strategies, SMOTE settings, outlier handling) from a central YAML config file.\n",
    "\n",
    "    - Defines hyperparameter search space using values specified in the config.\n",
    "\n",
    "  - Pipeline Construction (imblearn pipeline composed of)\n",
    "\n",
    "    - OutlierHandler (custom component)\n",
    "\n",
    "    - FeatureEncoder (with support for different encoding strategies)\n",
    "\n",
    "    - SMOTE to address class imbalance\n",
    "\n",
    "    - XGBoost Classifier as the final model\n",
    "\n",
    "    - Each component is parameterized for tuning.\n",
    "\n",
    "  - Hyperparameter Tuning\n",
    "\n",
    "    - Uses RandomizedSearchCV with cross-validation (cv=5) to explore a subset of combinations from a large parameter space.\n",
    "\n",
    "    - Randomized search allows balancing thoroughness and computational efficiency (n_iter=30 here).\n",
    "\n",
    "    - Includes tuning of model, preprocessing, and sampling strategiesâ€”making this a full pipeline optimization.\n",
    "\n",
    "  - Model Evaluation\n",
    "\n",
    "    - Evaluates the best-found model on both validation and test sets using classification metrics and confusion matrix.\n",
    "\n",
    "    - Returns a dictionary of performance metrics for downstream reporting.\n",
    "\n",
    "  - Feature Importance Visualization\n",
    "\n",
    "    - Extracts feature importances from the trained XGBoost model and displays the top features in a bar plot.\n",
    "\n",
    "    - Supports recovery of feature names even after transformation via pipeline components.\n",
    "\n",
    "\n",
    "Key Design Highlights\n",
    "\n",
    "- Configuration-driven design: All hyperparameter ranges, encoding strategies, and SMOTE settings are externally defined in config.yaml, allowing flexibility and separation of concerns.\n",
    "\n",
    "- Modular structure: Each stage of the pipeline is independently testable, extensible, and reusable.\n",
    "\n",
    "- Reproducibility: The random_state parameter ensures consistent results across runs.\n",
    "\n",
    "- Balanced tuning: Incorporates not just model hyperparameters, but also preprocessing decisions (e.g., outlier removal thresholds, encoding methods), providing a more realistic view of model performance.\n",
    "\n",
    "\n",
    "Default Parameters Used:\n",
    "\n",
    "- Test Set Size: 20%\n",
    "\n",
    "- Validation Set Size: 20% (of remaining training data)\n",
    "\n",
    "- Cross-Validation: 5-fold\n",
    "\n",
    "- Random Search Iterations: 30 combinations\n",
    "\n",
    "- Model: XGBoost (multi:softprob objective for multiclass classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.models.credit_score_pipeline as pipeline_module\n",
    "importlib.reload(pipeline_module)\n",
    "from src.models.credit_score_pipeline import CreditScorePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ndf_copy = df.drop(columns=[\"Customer_ID\"]) # Dropping the identifier column Customer_ID\\n\\n# Relative path from notebooks directory to config file\\nconfig_path = \"../config.yaml\"\\n\\n\\n\"\"\"Run the credit score classification pipeline.\"\"\"\\n\\n\\n# Separate features and target\\nX = df_copy.drop(\"Credit_Score\", axis=1)\\ny = df_copy[\"Credit_Score\"]\\n\\n# Initialize pipeline\\npipeline = CreditScorePipeline(config_path=config_path, random_state=42)\\n\\n# Run full pipeline\\nresults = pipeline.run_full_pipeline(\\n    X, y, \\n    test_size=0.2,\\n    val_size=0.2,\\n    n_iter=30,  # Number of hyperparameter combinations to try\\n    cv=5        # Number of cross-validation folds\\n)\\n\\n'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "df_copy = df.drop(columns=[\"Customer_ID\"]) # Dropping the identifier column Customer_ID\n",
    "\n",
    "# Relative path from notebooks directory to config file\n",
    "config_path = \"../config.yaml\"\n",
    "\n",
    "\n",
    "\"\"\"Run the credit score classification pipeline.\"\"\"\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = df_copy.drop(\"Credit_Score\", axis=1)\n",
    "y = df_copy[\"Credit_Score\"]\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = CreditScorePipeline(config_path=config_path, random_state=42)\n",
    "\n",
    "# Run full pipeline\n",
    "results = pipeline.run_full_pipeline(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    val_size=0.2,\n",
    "    n_iter=30,  # Number of hyperparameter combinations to try\n",
    "    cv=5        # Number of cross-validation folds\n",
    ")\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of results:\n",
    "\n",
    "- The model performs consistently well across all data splits (cross-validation, validation, and test), indicating good generalization and no evident overfitting.\n",
    "\n",
    "- High precision and recall across majority classes (especially for class 1 and class 2), with F1-scores ~0.98.\n",
    "\n",
    "- The confusion matrix confirms this, showing very few misclassifications and strong separation across classes.\n",
    "\n",
    "\n",
    "Potential Concerns & Biases:\n",
    " - Over-reliance on City feature\n",
    "\n",
    "   - The top four most important features are all related to the City variable (e.g., City_ZeroVille, City_Standhampton).\n",
    "\n",
    "   - Given prior observations that City categories showed perfect correlation with the target, this likely reflects data leakage or labeling artifacts.\n",
    "\n",
    "   - This inflates performance artificially and compromises model fairness and generalizability. It may also mask the true influence of more general financial behavior features.\n",
    "\n",
    " - Underweighting of key financial predictors\n",
    "\n",
    "   - Important behavioral features like Num_of_Delayed_Payment, Credit_Mix, and Loan_Count are ranked very low in importance.\n",
    "\n",
    "   - This may be a consequence of the model prioritizing easier-to-exploit categorical artifacts (City, Street), rather than genuinely predictive patterns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop column City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_copy = df.drop(columns=[\"Customer_ID\",\"City\"]) \\n\\n# Relative path from notebooks directory to config file\\nconfig_path = \"../config.yaml\"\\n\\n\\n\"\"\"Run the credit score classification pipeline.\"\"\"\\n\\n\\n# Separate features and target\\nX = df_copy.drop(\"Credit_Score\", axis=1)\\ny = df_copy[\"Credit_Score\"]\\n\\n# Initialize pipeline\\npipeline = CreditScorePipeline(config_path=config_path, random_state=42)\\n\\n# Run full pipeline\\nresults = pipeline.run_full_pipeline(\\n    X, y, \\n    test_size=0.2,\\n    val_size=0.2,\\n    n_iter=30,  # Number of hyperparameter combinations to try\\n    cv=5        # Number of cross-validation folds\\n)\\n\\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_copy = df.drop(columns=[\"Customer_ID\",\"City\"]) \n",
    "\n",
    "# Relative path from notebooks directory to config file\n",
    "config_path = \"../config.yaml\"\n",
    "\n",
    "\n",
    "\"\"\"Run the credit score classification pipeline.\"\"\"\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = df_copy.drop(\"Credit_Score\", axis=1)\n",
    "y = df_copy[\"Credit_Score\"]\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = CreditScorePipeline(config_path=config_path, random_state=42)\n",
    "\n",
    "# Run full pipeline\n",
    "results = pipeline.run_full_pipeline(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    val_size=0.2,\n",
    "    n_iter=30,  # Number of hyperparameter combinations to try\n",
    "    cv=5        # Number of cross-validation folds\n",
    ")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop both columns City and Street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_copy = df.drop(columns=[\"Customer_ID\",\"City\",\"Street\"]) \\n\\n# Relative path from notebooks directory to config file\\nconfig_path = \"../config.yaml\"\\n\\n\\n\"\"\"Run the credit score classification pipeline.\"\"\"\\n\\n\\n# Separate features and target\\nX = df_copy.drop(\"Credit_Score\", axis=1)\\ny = df_copy[\"Credit_Score\"]\\n\\n# Initialize pipeline\\npipeline = CreditScorePipeline(config_path=config_path, random_state=42)\\n\\n# Run full pipeline\\nresults = pipeline.run_full_pipeline(\\n    X, y, \\n    test_size=0.2,\\n    val_size=0.2,\\n    n_iter=30,  # Number of hyperparameter combinations to try\\n    cv=5        # Number of cross-validation folds\\n)\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_copy = df.drop(columns=[\"Customer_ID\",\"City\",\"Street\"]) \n",
    "\n",
    "# Relative path from notebooks directory to config file\n",
    "config_path = \"../config.yaml\"\n",
    "\n",
    "\n",
    "\"\"\"Run the credit score classification pipeline.\"\"\"\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = df_copy.drop(\"Credit_Score\", axis=1)\n",
    "y = df_copy[\"Credit_Score\"]\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = CreditScorePipeline(config_path=config_path, random_state=42)\n",
    "\n",
    "# Run full pipeline\n",
    "results = pipeline.run_full_pipeline(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    val_size=0.2,\n",
    "    n_iter=30,  # Number of hyperparameter combinations to try\n",
    "    cv=5        # Number of cross-validation folds\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer-based data split to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-based split using Customer_ID (then dropped) into train (800 customers, 6400 records), validation (200 customers, 1600 records), and test (250 customers, 2000 records) sets.\n",
      "Warning: Feature 'City' from config is not present in the data. Skipping.\n",
      "Warning: Feature 'Street' from config is not present in the data. Skipping.\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m pipeline = CreditScorePipeline(config_path=config_path, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Run full pipeline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m results = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_full_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of hyperparameter combinations to try\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Number of cross-validation folds\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_split\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustomer_id_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCustomer_ID\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     26\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\src\\models\\credit_score_pipeline.py:454\u001b[39m, in \u001b[36mCreditScorePipeline.run_full_pipeline\u001b[39m\u001b[34m(self, X, y, test_size, val_size, n_iter, cv, scoring, custom_split, customer_id_col)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28mself\u001b[39m.split_data(X, y, test_size=test_size, val_size=val_size, \n\u001b[32m    451\u001b[39m                custom_split=custom_split, customer_id_col=customer_id_col)\n\u001b[32m    453\u001b[39m \u001b[38;5;66;03m# Step 2: Tune hyperparameters\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtune_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# Step 3: Evaluate model\u001b[39;00m\n\u001b[32m    457\u001b[39m evaluation_metrics = \u001b[38;5;28mself\u001b[39m.evaluate_model()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\src\\models\\credit_score_pipeline.py:280\u001b[39m, in \u001b[36mCreditScorePipeline.tune_hyperparameters\u001b[39m\u001b[34m(self, n_iter, cv, scoring, n_jobs)\u001b[39m\n\u001b[32m    267\u001b[39m random_search = RandomizedSearchCV(\n\u001b[32m    268\u001b[39m     pipeline,\n\u001b[32m    269\u001b[39m     param_distributions=\u001b[38;5;28mself\u001b[39m.param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m    276\u001b[39m     return_train_score=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    277\u001b[39m )\n\u001b[32m    279\u001b[39m \u001b[38;5;66;03m# Fit random search on train data - imblearn Pipeline handles SMOTE correctly\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[38;5;28mself\u001b[39m.best_model = random_search\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Print best parameters across all cross-validation folds\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "df_copy = df.drop(columns=[\"City\",\"Street\"]) \n",
    "\n",
    "# Relative path from notebooks directory to config file\n",
    "config_path = \"../config.yaml\"\n",
    "\n",
    "\n",
    "\"\"\"Run the credit score classification pipeline.\"\"\"\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = df_copy.drop(\"Credit_Score\", axis=1)\n",
    "y = df_copy[\"Credit_Score\"]\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = CreditScorePipeline(config_path=config_path, random_state=42)\n",
    "\n",
    "# Run full pipeline\n",
    "results = pipeline.run_full_pipeline(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    val_size=0.2,\n",
    "    n_iter=30,  # Number of hyperparameter combinations to try\n",
    "    cv=5,        # Number of cross-validation folds\n",
    "    custom_split=True,\n",
    "    customer_id_col=\"Customer_ID\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated dataset with unique customers records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from c:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\data\\processed\\aggregated_dataset.csv\n",
      "Loaded dataset with 12500 rows and 32 columns\n"
     ]
    }
   ],
   "source": [
    "script_dir  = pathlib.Path.cwd()              \n",
    "project_root = script_dir.parent\n",
    "\n",
    "file_path_aggregated_df = project_root / 'data' / 'processed' / 'aggregated_dataset.csv'\n",
    "\n",
    "df_aggregated = load_data(str(file_path_aggregated_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random split into train (6400 records), validation (1600 records), and test (2000 records) sets.\n",
      "Warning: Feature 'Month' from config is not present in the data. Skipping.\n",
      "Warning: Feature 'City' from config is not present in the data. Skipping.\n",
      "Warning: Feature 'Street' from config is not present in the data. Skipping.\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[97]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m pipeline = CreditScorePipeline(config_path=config_path, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Run full pipeline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m results = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_full_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of hyperparameter combinations to try\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Number of cross-validation folds\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\src\\models\\credit_score_pipeline.py:454\u001b[39m, in \u001b[36mCreditScorePipeline.run_full_pipeline\u001b[39m\u001b[34m(self, X, y, test_size, val_size, n_iter, cv, scoring, custom_split, customer_id_col)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28mself\u001b[39m.split_data(X, y, test_size=test_size, val_size=val_size, \n\u001b[32m    451\u001b[39m                custom_split=custom_split, customer_id_col=customer_id_col)\n\u001b[32m    453\u001b[39m \u001b[38;5;66;03m# Step 2: Tune hyperparameters\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtune_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# Step 3: Evaluate model\u001b[39;00m\n\u001b[32m    457\u001b[39m evaluation_metrics = \u001b[38;5;28mself\u001b[39m.evaluate_model()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\src\\models\\credit_score_pipeline.py:280\u001b[39m, in \u001b[36mCreditScorePipeline.tune_hyperparameters\u001b[39m\u001b[34m(self, n_iter, cv, scoring, n_jobs)\u001b[39m\n\u001b[32m    267\u001b[39m random_search = RandomizedSearchCV(\n\u001b[32m    268\u001b[39m     pipeline,\n\u001b[32m    269\u001b[39m     param_distributions=\u001b[38;5;28mself\u001b[39m.param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m    276\u001b[39m     return_train_score=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    277\u001b[39m )\n\u001b[32m    279\u001b[39m \u001b[38;5;66;03m# Fit random search on train data - imblearn Pipeline handles SMOTE correctly\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[38;5;28mself\u001b[39m.best_model = random_search\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Print best parameters across all cross-validation folds\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Utente\\Desktop\\STUDIO\\LUISS\\ANNO_3\\Advanced_Coding\\Credit_Score_Classification\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "df_copy = df.drop(columns=[\"Customer_ID\", \"Month\", \"City\", \"Street\"]) # Dropping the identifier column Customer_ID\n",
    "\n",
    "# Relative path from notebooks directory to config file\n",
    "config_path = \"../config.yaml\"\n",
    "\n",
    "\n",
    "\"\"\"Run the credit score classification pipeline.\"\"\"\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = df_copy.drop(\"Credit_Score\", axis=1)\n",
    "y = df_copy[\"Credit_Score\"]\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = CreditScorePipeline(config_path=config_path, random_state=42)\n",
    "\n",
    "# Run full pipeline\n",
    "results = pipeline.run_full_pipeline(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    val_size=0.2,\n",
    "    n_iter=30,  # Number of hyperparameter combinations to try\n",
    "    cv=5        # Number of cross-validation folds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
